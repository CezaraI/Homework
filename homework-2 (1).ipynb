


{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf99c4f9",
   "metadata": {
    "papermill": {
     "duration": 0.005155,
     "end_time": "2025-10-27T20:35:06.948846",
     "exception": false,
     "start_time": "2025-10-27T20:35:06.943691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84237303",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:06.959707Z",
     "iopub.status.busy": "2025-10-27T20:35:06.958990Z",
     "iopub.status.idle": "2025-10-27T20:35:17.879508Z",
     "shell.execute_reply": "2025-10-27T20:35:17.878698Z"
    },
    "papermill": {
     "duration": 10.926924,
     "end_time": "2025-10-27T20:35:17.880836",
     "exception": false,
     "start_time": "2025-10-27T20:35:06.953912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision.transforms import v2\n",
    "from torch.backends import cudnn\n",
    "from torch import GradScaler\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "\n",
    "\n",
    "#Adding seed for reproducibility\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(f\"Random seed set to {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbe09b",
   "metadata": {
    "papermill": {
     "duration": 0.003961,
     "end_time": "2025-10-27T20:35:17.889260",
     "exception": false,
     "start_time": "2025-10-27T20:35:17.885299",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Device setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395dfd83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:17.898248Z",
     "iopub.status.busy": "2025-10-27T20:35:17.897908Z",
     "iopub.status.idle": "2025-10-27T20:35:17.983137Z",
     "shell.execute_reply": "2025-10-27T20:35:17.982467Z"
    },
    "papermill": {
     "duration": 0.090971,
     "end_time": "2025-10-27T20:35:17.984292",
     "exception": false,
     "start_time": "2025-10-27T20:35:17.893321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad scaler is enabled: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else torch.device(\"cpu\")\n",
    "enable_half = device.type != \"cpu\"\n",
    "scaler = GradScaler(device, enabled=enable_half)\n",
    "\n",
    "print(\"Grad scaler is enabled:\", enable_half)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d01301",
   "metadata": {
    "papermill": {
     "duration": 0.004161,
     "end_time": "2025-10-27T20:35:17.992915",
     "exception": false,
     "start_time": "2025-10-27T20:35:17.988754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Dataset loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08c1914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:18.002424Z",
     "iopub.status.busy": "2025-10-27T20:35:18.001919Z",
     "iopub.status.idle": "2025-10-27T20:35:18.006311Z",
     "shell.execute_reply": "2025-10-27T20:35:18.005609Z"
    },
    "papermill": {
     "duration": 0.010189,
     "end_time": "2025-10-27T20:35:18.007355",
     "exception": false,
     "start_time": "2025-10-27T20:35:17.997166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Kaggle.\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"/kaggle/input\") and os.path.exists(\"/kaggle/working\"):\n",
    "    print(\"Running on Kaggle.\")\n",
    "    SVHN_test = \"/kaggle/input/fii-atnn-2025-competition-2/SVHN_test.pkl\"\n",
    "    SVHN_train = \"/kaggle/input/fii-atnn-2025-competition-2/SVHN_train.pkl\"\n",
    "else:\n",
    "    print(\"Not on Kaggle.\")\n",
    "    SVHN_test = \"data/SVHN_test.pkl\"\n",
    "    SVHN_train = \"data/SVHN_train.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0091ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:18.016814Z",
     "iopub.status.busy": "2025-10-27T20:35:18.016424Z",
     "iopub.status.idle": "2025-10-27T20:35:18.020819Z",
     "shell.execute_reply": "2025-10-27T20:35:18.020311Z"
    },
    "papermill": {
     "duration": 0.010057,
     "end_time": "2025-10-27T20:35:18.021834",
     "exception": false,
     "start_time": "2025-10-27T20:35:18.011777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SVHN_Dataset(Dataset):\n",
    "    def __init__(self, train: bool, transforms: v2.Transform):\n",
    "        path = SVHN_test\n",
    "        if train:\n",
    "            path = SVHN_train\n",
    "        with open(path, \"rb\") as fd:\n",
    "            self.data = pickle.load(fd)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        image, label = self.data[i]\n",
    "        if self.transforms is None:\n",
    "            return image, label\n",
    "        return self.transforms(image), label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a1848",
   "metadata": {
    "papermill": {
     "duration": 0.004123,
     "end_time": "2025-10-27T20:35:18.030414",
     "exception": false,
     "start_time": "2025-10-27T20:35:18.026291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Data preprocessing and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93816c96",
   "metadata": {
    "papermill": {
     "duration": 0.003999,
     "end_time": "2025-10-27T20:35:18.038541",
     "exception": false,
     "start_time": "2025-10-27T20:35:18.034542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49b2d16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:18.047566Z",
     "iopub.status.busy": "2025-10-27T20:35:18.047356Z",
     "iopub.status.idle": "2025-10-27T20:35:18.050734Z",
     "shell.execute_reply": "2025-10-27T20:35:18.050188Z"
    },
    "papermill": {
     "duration": 0.009113,
     "end_time": "2025-10-27T20:35:18.051699",
     "exception": false,
     "start_time": "2025-10-27T20:35:18.042586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # basic_transforms = v2.Compose([\n",
    "# #     v2.ToImage(),\n",
    "# #     v2.ToDtype(torch.float32, scale=True),\n",
    "# #     v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n",
    "# # ])\n",
    "\n",
    "# # Training transforms (with mirroring)\n",
    "# train_transforms = v2.Compose([\n",
    "#     v2.ToImage(),\n",
    "#     v2.ToDtype(torch.float32, scale=True),\n",
    "#     v2.RandomHorizontalFlip(),  # <-- mirroring\n",
    "#     v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n",
    "# ])\n",
    "\n",
    "# # Test transforms (no mirroring)\n",
    "# test_transforms = v2.Compose([\n",
    "#     v2.ToImage(),\n",
    "#     v2.ToDtype(torch.float32, scale=True),\n",
    "#     v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n",
    "# ])\n",
    "\n",
    "# # Datasets\n",
    "# train_set = SVHN_Dataset(train=True, transforms=train_transforms)\n",
    "# test_set = SVHN_Dataset(train=False, transforms=test_transforms)\n",
    "\n",
    "# # DataLoaders\n",
    "# train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_set, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a3a7d",
   "metadata": {
    "papermill": {
     "duration": 0.004048,
     "end_time": "2025-10-27T20:35:18.060329",
     "exception": false,
     "start_time": "2025-10-27T20:35:18.056281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfdba5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:18.069597Z",
     "iopub.status.busy": "2025-10-27T20:35:18.069402Z",
     "iopub.status.idle": "2025-10-27T20:35:25.823338Z",
     "shell.execute_reply": "2025-10-27T20:35:25.822685Z"
    },
    "papermill": {
     "duration": 7.760291,
     "end_time": "2025-10-27T20:35:25.824682",
     "exception": false,
     "start_time": "2025-10-27T20:35:18.064391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "\n",
    "    v2.RandomCrop(32, padding=4),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "\n",
    "    v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25)),\n",
    "])\n",
    "\n",
    "\n",
    "# Test transforms (no mirroring)\n",
    "test_transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_set = SVHN_Dataset(train=True, transforms=train_transforms)\n",
    "test_set = SVHN_Dataset(train=False, transforms=test_transforms)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7effb0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:25.834578Z",
     "iopub.status.busy": "2025-10-27T20:35:25.834350Z",
     "iopub.status.idle": "2025-10-27T20:35:25.842403Z",
     "shell.execute_reply": "2025-10-27T20:35:25.841676Z"
    },
    "papermill": {
     "duration": 0.014116,
     "end_time": "2025-10-27T20:35:25.843428",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.829312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG13(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG13, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Block 5\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Classifier\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b636ae6",
   "metadata": {
    "papermill": {
     "duration": 0.003955,
     "end_time": "2025-10-27T20:35:25.851542",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.847587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 3: Cutmix and Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d53eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:25.860895Z",
     "iopub.status.busy": "2025-10-27T20:35:25.860279Z",
     "iopub.status.idle": "2025-10-27T20:35:25.868920Z",
     "shell.execute_reply": "2025-10-27T20:35:25.868205Z"
    },
    "papermill": {
     "duration": 0.014468,
     "end_time": "2025-10-27T20:35:25.870027",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.855559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    \"\"\"Generate random bounding box.\"\"\"\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    # uniform center\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    \"\"\"Applies MixUp augmentation.\"\"\"\n",
    "    if alpha <= 0:\n",
    "        return x, y, y, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    \"\"\"Applies CutMix augmentation.\"\"\"\n",
    "    if alpha <= 0:\n",
    "        return x, y, y, 1.0\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n",
    "    y_a, y_b = y, y[index]\n",
    "    return x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def criterion_mixup_cutmix(criterion, preds, y_a, y_b, lam):\n",
    "    \"\"\"Computes loss for mixed labels.\"\"\"\n",
    "    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eeeeaa",
   "metadata": {
    "papermill": {
     "duration": 0.003909,
     "end_time": "2025-10-27T20:35:25.878104",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.874195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Model setup: Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3744a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:25.886973Z",
     "iopub.status.busy": "2025-10-27T20:35:25.886777Z",
     "iopub.status.idle": "2025-10-27T20:35:25.889537Z",
     "shell.execute_reply": "2025-10-27T20:35:25.889043Z"
    },
    "papermill": {
     "duration": 0.008352,
     "end_time": "2025-10-27T20:35:25.890557",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.882205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = VGG13().to(device)\n",
    "# model = torch.jit.script(model)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001, fused=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d97298",
   "metadata": {
    "papermill": {
     "duration": 0.004115,
     "end_time": "2025-10-27T20:35:25.898868",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.894753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 1: Using Adam optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac209f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:25.907979Z",
     "iopub.status.busy": "2025-10-27T20:35:25.907694Z",
     "iopub.status.idle": "2025-10-27T20:35:25.910809Z",
     "shell.execute_reply": "2025-10-27T20:35:25.910126Z"
    },
    "papermill": {
     "duration": 0.00882,
     "end_time": "2025-10-27T20:35:25.911823",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.903003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = VGG13().to(device)\n",
    "# # Remove scripting if using features that may not be compatible with Adam\n",
    "# # model = torch.jit.script(model)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Use Adam optimizer\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Optional: Learning rate scheduler (ReduceLROnPlateau)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     optimizer, mode='max', factor=0.5, patience=2\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77132b",
   "metadata": {
    "papermill": {
     "duration": 0.00398,
     "end_time": "2025-10-27T20:35:25.920067",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.916087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 2:Adam+CosineAnnealing+LAbelSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad71dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:25.929580Z",
     "iopub.status.busy": "2025-10-27T20:35:25.928902Z",
     "iopub.status.idle": "2025-10-27T20:35:26.160969Z",
     "shell.execute_reply": "2025-10-27T20:35:26.160189Z"
    },
    "papermill": {
     "duration": 0.23815,
     "end_time": "2025-10-27T20:35:26.162359",
     "exception": false,
     "start_time": "2025-10-27T20:35:25.924209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VGG13().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=100,         \n",
    "    eta_min=1e-5       \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a362ace",
   "metadata": {
    "papermill": {
     "duration": 0.00421,
     "end_time": "2025-10-27T20:35:26.171201",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.166991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 1:Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1528bf05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:26.180618Z",
     "iopub.status.busy": "2025-10-27T20:35:26.180382Z",
     "iopub.status.idle": "2025-10-27T20:35:26.183898Z",
     "shell.execute_reply": "2025-10-27T20:35:26.183197Z"
    },
    "papermill": {
     "duration": 0.009444,
     "end_time": "2025-10-27T20:35:26.184998",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.175554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     model.train()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     for inputs, targets in train_loader:\n",
    "#         inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "#         with torch.autocast(device.type, enabled=enable_half):\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#         scaler.scale(loss).backward()\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         predicted = outputs.argmax(1)\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#     return 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33e5d8",
   "metadata": {
    "papermill": {
     "duration": 0.004037,
     "end_time": "2025-10-27T20:35:26.193172",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.189135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 3:Training function with cutmix and mixup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7f0fe4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:26.202050Z",
     "iopub.status.busy": "2025-10-27T20:35:26.201849Z",
     "iopub.status.idle": "2025-10-27T20:35:26.208370Z",
     "shell.execute_reply": "2025-10-27T20:35:26.207843Z"
    },
    "papermill": {
     "duration": 0.012147,
     "end_time": "2025-10-27T20:35:26.209363",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.197216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    correct, total, total_loss = 0, 0, 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Randomly choose augmentation type\n",
    "        aug_type = random.choice([\"none\", \"mixup\", \"cutmix\"])\n",
    "        if aug_type == \"mixup\":\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=1.0)\n",
    "        elif aug_type == \"cutmix\":\n",
    "            inputs, targets_a, targets_b, lam = cutmix_data(inputs, targets, alpha=1.0)\n",
    "        else:\n",
    "            lam = 1.0  # No augmentation\n",
    "\n",
    "        with torch.autocast(device_type=device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "            if aug_type in [\"mixup\", \"cutmix\"]:\n",
    "                loss = criterion_mixup_cutmix(criterion, outputs, targets_a, targets_b, lam)\n",
    "            else:\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item() * targets.size(0)\n",
    "        predicted = outputs.argmax(1)\n",
    "        total += targets.size(0)\n",
    "        if aug_type == \"none\":\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        else:\n",
    "            # Mixed-label accuracy not exact — use soft metric\n",
    "            correct += (lam * predicted.eq(targets_a).sum().item() +\n",
    "                        (1 - lam) * predicted.eq(targets_b).sum().item())\n",
    "\n",
    "    return 100.0 * correct / total, total_loss / total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4846f1",
   "metadata": {
    "papermill": {
     "duration": 0.00395,
     "end_time": "2025-10-27T20:35:26.217459",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.213509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5494644d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:26.226434Z",
     "iopub.status.busy": "2025-10-27T20:35:26.226229Z",
     "iopub.status.idle": "2025-10-27T20:35:26.230317Z",
     "shell.execute_reply": "2025-10-27T20:35:26.229763Z"
    },
    "papermill": {
     "duration": 0.009713,
     "end_time": "2025-10-27T20:35:26.231248",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.221535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def inference():\n",
    "    model.eval()\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        with torch.autocast(device.type, enabled=enable_half):\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        predicted = outputs.argmax(1).tolist()\n",
    "        labels.extend(predicted)\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbcb70a",
   "metadata": {
    "papermill": {
     "duration": 0.003944,
     "end_time": "2025-10-27T20:35:26.239283",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.235339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d59e1c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:26.248691Z",
     "iopub.status.busy": "2025-10-27T20:35:26.248493Z",
     "iopub.status.idle": "2025-10-27T20:35:26.251670Z",
     "shell.execute_reply": "2025-10-27T20:35:26.251111Z"
    },
    "papermill": {
     "duration": 0.009252,
     "end_time": "2025-10-27T20:35:26.252728",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.243476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best = 0.0\n",
    "# best_epoch = 0\n",
    "# epochs = list(range(50))  # increase epochs; early stopping will break early\n",
    "# patience = 3\n",
    "# no_improve = 0\n",
    "\n",
    "# with tqdm(epochs) as tbar:\n",
    "#     for epoch in tbar:\n",
    "#         train_acc = train()\n",
    "\n",
    "#         # Step the LR scheduler\n",
    "#         scheduler.step(train_acc)\n",
    "\n",
    "#         # Checkpoint saving\n",
    "#         if train_acc > best:\n",
    "#             best = train_acc\n",
    "#             best_epoch = epoch\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#             no_improve = 0\n",
    "#         else:\n",
    "#             no_improve += 1\n",
    "\n",
    "#         # Early stopping\n",
    "#         if no_improve >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch}\")\n",
    "#             break\n",
    "\n",
    "#         tbar.set_description(f\"Train: {train_acc:.2f}, Best: {best:.2f} at epoch {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a298e",
   "metadata": {
    "papermill": {
     "duration": 0.004088,
     "end_time": "2025-10-27T20:35:26.261119",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.257031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f420c424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:26.270465Z",
     "iopub.status.busy": "2025-10-27T20:35:26.270055Z",
     "iopub.status.idle": "2025-10-27T20:35:26.273334Z",
     "shell.execute_reply": "2025-10-27T20:35:26.272760Z"
    },
    "papermill": {
     "duration": 0.008973,
     "end_time": "2025-10-27T20:35:26.274315",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.265342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best = 0.0\n",
    "# best_epoch = 0\n",
    "# epochs = list(range(100))  # increase epochs; early stopping will break early\n",
    "# patience = 3\n",
    "# no_improve = 0\n",
    "\n",
    "# with tqdm(epochs) as tbar:\n",
    "#     for epoch in tbar:\n",
    "#         train_acc = train()\n",
    "\n",
    "#         # Step the LR scheduler\n",
    "#         scheduler.step(train_acc)\n",
    "\n",
    "#         # Checkpoint saving\n",
    "#         if train_acc > best:\n",
    "#             best = train_acc\n",
    "#             best_epoch = epoch\n",
    "#             torch.save(model.state_dict(), \"best_model.pth\")\n",
    "#             no_improve = 0\n",
    "#         else:\n",
    "#             no_improve += 1\n",
    "\n",
    "#         # Early stopping\n",
    "#         if no_improve >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch}\")\n",
    "#             break\n",
    "\n",
    "#         tbar.set_description(f\"Train: {train_acc:.2f}, Best: {best:.2f} at epoch {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fabb8a5",
   "metadata": {
    "papermill": {
     "duration": 0.003998,
     "end_time": "2025-10-27T20:35:26.282552",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.278554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5590ec34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T20:35:26.291785Z",
     "iopub.status.busy": "2025-10-27T20:35:26.291587Z",
     "iopub.status.idle": "2025-10-27T21:24:38.170225Z",
     "shell.execute_reply": "2025-10-27T21:24:38.169445Z"
    },
    "papermill": {
     "duration": 2951.892301,
     "end_time": "2025-10-27T21:24:38.179010",
     "exception": false,
     "start_time": "2025-10-27T20:35:26.286709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 57.26, Best: 57.81 at epoch 38:  41%|████      | 41/100 [49:11<1:10:47, 72.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best = 0.0\n",
    "best_epoch = 0\n",
    "epochs = list(range(100))  # increase epochs; early stopping will break early\n",
    "patience = 3\n",
    "no_improve = 0\n",
    "\n",
    "with tqdm(epochs) as tbar:\n",
    "    for epoch in tbar:\n",
    "        train_acc, _ = train()   # <-- unpack tuple\n",
    "\n",
    "        # Step the LR scheduler\n",
    "        scheduler.step()  # keep as is for CosineAnnealing\n",
    "\n",
    "        # Checkpoint saving\n",
    "        if train_acc > best:\n",
    "            best = train_acc\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if no_improve >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "        tbar.set_description(f\"Train: {train_acc:.2f}, Best: {best:.2f} at epoch {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d23fd30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T21:24:38.194991Z",
     "iopub.status.busy": "2025-10-27T21:24:38.194768Z",
     "iopub.status.idle": "2025-10-27T21:24:40.256706Z",
     "shell.execute_reply": "2025-10-27T21:24:40.255914Z"
    },
    "papermill": {
     "duration": 2.071366,
     "end_time": "2025-10-27T21:24:40.258066",
     "exception": false,
     "start_time": "2025-10-27T21:24:38.186700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the best checkpoint\n",
    "# if os.path.exists(\"best_model.pth\"):\n",
    "#     model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "#     print(\"Loaded best model checkpoint.\")\n",
    "# else:\n",
    "#     print(\"No checkpoint found, using current model.\")\n",
    "\n",
    "# Prepare submission\n",
    "data = {\n",
    "    \"ID\": [],\n",
    "    \"target\": []\n",
    "}\n",
    "\n",
    "for i, label in enumerate(inference()):\n",
    "    data[\"ID\"].append(i)\n",
    "    data[\"target\"].append(label)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14027336,
     "sourceId": 117336,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2978.728519,
   "end_time": "2025-10-27T21:24:41.987447",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-27T20:35:03.258928",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
