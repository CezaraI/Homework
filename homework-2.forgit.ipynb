{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117336,"databundleVersionId":14027336,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports and setup","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport torch\nfrom torch import nn, Tensor\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom torchvision.transforms import v2\nfrom torch.backends import cudnn\nfrom torch import GradScaler\nfrom torch import optim\nfrom tqdm import tqdm\nimport numpy as np\nimport pickle\nfrom torchvision.transforms import v2\n\n\n\n#Adding seed for reproducibility\n\nseed = 42\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nprint(f\"Random seed set to {seed}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:23.818078Z","iopub.execute_input":"2025-10-27T18:11:23.818321Z","iopub.status.idle":"2025-10-27T18:11:27.406726Z","shell.execute_reply.started":"2025-10-27T18:11:23.818298Z","shell.execute_reply":"2025-10-27T18:11:27.405923Z"}},"outputs":[{"name":"stdout","text":"Random seed set to 42\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"Device setup\n","metadata":{}},{"cell_type":"code","source":"device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else torch.device(\"cpu\")\nenable_half = device.type != \"cpu\"\nscaler = GradScaler(device, enabled=enable_half)\n\nprint(\"Grad scaler is enabled:\", enable_half)\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.407666Z","iopub.execute_input":"2025-10-27T18:11:27.408305Z","iopub.status.idle":"2025-10-27T18:11:27.467973Z","shell.execute_reply.started":"2025-10-27T18:11:27.408274Z","shell.execute_reply":"2025-10-27T18:11:27.467425Z"}},"outputs":[{"name":"stdout","text":"Grad scaler is enabled: True\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"Dataset loading\n","metadata":{}},{"cell_type":"code","source":"if os.path.exists(\"/kaggle/input\") and os.path.exists(\"/kaggle/working\"):\n    print(\"Running on Kaggle.\")\n    SVHN_test = \"/kaggle/input/fii-atnn-2025-competition-2/SVHN_test.pkl\"\n    SVHN_train = \"/kaggle/input/fii-atnn-2025-competition-2/SVHN_train.pkl\"\nelse:\n    print(\"Not on Kaggle.\")\n    SVHN_test = \"data/SVHN_test.pkl\"\n    SVHN_train = \"data/SVHN_train.pkl\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.468667Z","iopub.execute_input":"2025-10-27T18:11:27.468870Z","iopub.status.idle":"2025-10-27T18:11:27.473308Z","shell.execute_reply.started":"2025-10-27T18:11:27.468852Z","shell.execute_reply":"2025-10-27T18:11:27.472610Z"}},"outputs":[{"name":"stdout","text":"Running on Kaggle.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class SVHN_Dataset(Dataset):\n    def __init__(self, train: bool, transforms: v2.Transform):\n        path = SVHN_test\n        if train:\n            path = SVHN_train\n        with open(path, \"rb\") as fd:\n            self.data = pickle.load(fd)\n\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, i: int):\n        image, label = self.data[i]\n        if self.transforms is None:\n            return image, label\n        return self.transforms(image), label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.475282Z","iopub.execute_input":"2025-10-27T18:11:27.475511Z","iopub.status.idle":"2025-10-27T18:11:27.486799Z","shell.execute_reply.started":"2025-10-27T18:11:27.475496Z","shell.execute_reply":"2025-10-27T18:11:27.486180Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Data preprocessing and dataloader","metadata":{}},{"cell_type":"markdown","source":"Experiment 1 and 4","metadata":{}},{"cell_type":"code","source":"# basic_transforms = v2.Compose([\n#     v2.ToImage(),\n#     v2.ToDtype(torch.float32, scale=True),\n#     v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n# ])\n\n# Training transforms (with mirroring)\ntrain_transforms = v2.Compose([\n    v2.ToImage(),\n    v2.ToDtype(torch.float32, scale=True),\n    v2.RandomHorizontalFlip(),  # <-- mirroring\n    v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n])\n\n# Test transforms (no mirroring)\ntest_transforms = v2.Compose([\n    v2.ToImage(),\n    v2.ToDtype(torch.float32, scale=True),\n    v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n])\n\n# Datasets\ntrain_set = SVHN_Dataset(train=True, transforms=train_transforms)\ntest_set = SVHN_Dataset(train=False, transforms=test_transforms)\n\n# DataLoaders\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.487549Z","iopub.execute_input":"2025-10-27T18:11:27.487784Z","iopub.status.idle":"2025-10-27T18:11:27.505888Z","shell.execute_reply.started":"2025-10-27T18:11:27.487767Z","shell.execute_reply":"2025-10-27T18:11:27.505357Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Experiment 2 and 3","metadata":{}},{"cell_type":"code","source":"# train_transforms = v2.Compose([\n#     v2.ToImage(),\n#     v2.ToDtype(torch.float32, scale=True),\n\n#     v2.RandomCrop(32, padding=4),\n#     v2.RandomHorizontalFlip(p=0.5),\n#     v2.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n#     v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n\n#     v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25)),\n# ])\n\n\n# # Test transforms (no mirroring)\n# test_transforms = v2.Compose([\n#     v2.ToImage(),\n#     v2.ToDtype(torch.float32, scale=True),\n#     v2.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25), inplace=True)\n# ])\n\n# # Datasets\n# train_set = SVHN_Dataset(train=True, transforms=train_transforms)\n# test_set = SVHN_Dataset(train=False, transforms=test_transforms)\n\n# # DataLoaders\n# train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n# test_loader = DataLoader(test_set, batch_size=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.506617Z","iopub.execute_input":"2025-10-27T18:11:27.507248Z","iopub.status.idle":"2025-10-27T18:11:27.851076Z","shell.execute_reply.started":"2025-10-27T18:11:27.507226Z","shell.execute_reply":"2025-10-27T18:11:27.850485Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class VGG13(nn.Module):\n    def __init__(self):\n        super(VGG13, self).__init__()\n\n        self.layers = nn.Sequential(\n            # Block 1\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 2\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 3\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 4\n            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Block 5\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            # Classifier\n            nn.Flatten(),\n            nn.Linear(512, 100)\n        )\n\n    def forward(self, x: Tensor) -> Tensor:\n        return self.layers(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.851752Z","iopub.execute_input":"2025-10-27T18:11:27.852010Z","iopub.status.idle":"2025-10-27T18:11:27.860709Z","shell.execute_reply.started":"2025-10-27T18:11:27.851987Z","shell.execute_reply":"2025-10-27T18:11:27.860098Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Experiment 3: Cutmix and Mixup","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef rand_bbox(size, lam):\n    \"\"\"Generate random bounding box.\"\"\"\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = int(W * cut_rat)\n    cut_h = int(H * cut_rat)\n\n    # uniform center\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\n\ndef mixup_data(x, y, alpha=1.0):\n    \"\"\"Applies MixUp augmentation.\"\"\"\n    if alpha <= 0:\n        return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef cutmix_data(x, y, alpha=1.0):\n    \"\"\"Applies CutMix augmentation.\"\"\"\n    if alpha <= 0:\n        return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n\n    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n\n    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size()[-1] * x.size()[-2]))\n    y_a, y_b = y, y[index]\n    return x, y_a, y_b, lam\n\n\ndef criterion_mixup_cutmix(criterion, preds, y_a, y_b, lam):\n    \"\"\"Computes loss for mixed labels.\"\"\"\n    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Model setup: Basic setup","metadata":{}},{"cell_type":"code","source":"# model = VGG13().to(device)\n# model = torch.jit.script(model)\n# criterion = nn.CrossEntropyLoss()\n# optimizer = optim.SGD(model.parameters(), lr=0.001, fused=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.861306Z","iopub.execute_input":"2025-10-27T18:11:27.861505Z","iopub.status.idle":"2025-10-27T18:11:27.880226Z","shell.execute_reply.started":"2025-10-27T18:11:27.861480Z","shell.execute_reply":"2025-10-27T18:11:27.879611Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Experiment 1: Using Adam optimizer\n","metadata":{}},{"cell_type":"code","source":"# model = VGG13().to(device)\n# # Remove scripting if using features that may not be compatible with Adam\n# # model = torch.jit.script(model)\n\n# criterion = nn.CrossEntropyLoss()\n\n# # Use Adam optimizer\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# # Optional: Learning rate scheduler (ReduceLROnPlateau)\n# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n#     optimizer, mode='max', factor=0.5, patience=2\n# )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:27.880866Z","iopub.execute_input":"2025-10-27T18:11:27.881109Z","iopub.status.idle":"2025-10-27T18:11:28.082741Z","shell.execute_reply.started":"2025-10-27T18:11:27.881087Z","shell.execute_reply":"2025-10-27T18:11:28.082182Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Experiment 2 and 3:Adam+CosineAnnealing+LAbelSmoothing","metadata":{}},{"cell_type":"code","source":"# model = VGG13().to(device)\n\n# criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n# optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n#     optimizer,\n#     T_max=100,         \n#     eta_min=1e-5       \n# )\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Experiment 4: SGD+CossineA+LabelS","metadata":{}},{"cell_type":"code","source":"model = VGG13().to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=100,         \n    eta_min=1e-5       \n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Experiment 1 and 2 and 4:Training function","metadata":{}},{"cell_type":"code","source":"def train():\n    model.train()\n    correct = 0\n    total = 0\n\n    for inputs, targets in train_loader:\n        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n        with torch.autocast(device.type, enabled=enable_half):\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n\n        predicted = outputs.argmax(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n    return 100.0 * correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:28.083727Z","iopub.execute_input":"2025-10-27T18:11:28.084106Z","iopub.status.idle":"2025-10-27T18:11:28.089025Z","shell.execute_reply.started":"2025-10-27T18:11:28.084073Z","shell.execute_reply":"2025-10-27T18:11:28.088395Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Experiment 3:Training function with cutmix and mixup\n","metadata":{}},{"cell_type":"code","source":"# def train():\n#     model.train()\n#     correct, total, total_loss = 0, 0, 0.0\n\n#     for inputs, targets in train_loader:\n#         inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n#         optimizer.zero_grad(set_to_none=True)\n\n#         # Randomly choose augmentation type\n#         aug_type = random.choice([\"none\", \"mixup\", \"cutmix\"])\n#         if aug_type == \"mixup\":\n#             inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=1.0)\n#         elif aug_type == \"cutmix\":\n#             inputs, targets_a, targets_b, lam = cutmix_data(inputs, targets, alpha=1.0)\n#         else:\n#             lam = 1.0  # No augmentation\n\n#         with torch.autocast(device_type=device.type, enabled=enable_half):\n#             outputs = model(inputs)\n#             if aug_type in [\"mixup\", \"cutmix\"]:\n#                 loss = criterion_mixup_cutmix(criterion, outputs, targets_a, targets_b, lam)\n#             else:\n#                 loss = criterion(outputs, targets)\n\n#         scaler.scale(loss).backward()\n#         scaler.step(optimizer)\n#         scaler.update()\n\n#         total_loss += loss.item() * targets.size(0)\n#         predicted = outputs.argmax(1)\n#         total += targets.size(0)\n#         if aug_type == \"none\":\n#             correct += predicted.eq(targets).sum().item()\n#         else:\n#             # Mixed-label accuracy not exact — use soft metric\n#             correct += (lam * predicted.eq(targets_a).sum().item() +\n#                         (1 - lam) * predicted.eq(targets_b).sum().item())\n\n#     return 100.0 * correct / total, total_loss / total\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Inference","metadata":{}},{"cell_type":"code","source":"@torch.inference_mode()\ndef inference():\n    model.eval()\n\n    labels = []\n\n    for inputs, _ in test_loader:\n        inputs = inputs.to(device, non_blocking=True)\n        with torch.autocast(device.type, enabled=enable_half):\n            outputs = model(inputs)\n\n        predicted = outputs.argmax(1).tolist()\n        labels.extend(predicted)\n\n    return labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:28.089739Z","iopub.execute_input":"2025-10-27T18:11:28.089933Z","iopub.status.idle":"2025-10-27T18:11:28.102969Z","shell.execute_reply.started":"2025-10-27T18:11:28.089913Z","shell.execute_reply":"2025-10-27T18:11:28.102402Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"Experiment 1 and 4:","metadata":{}},{"cell_type":"code","source":"best = 0.0\nbest_epoch = 0\nepochs = list(range(50))  # increase epochs; early stopping will break early\npatience = 3\nno_improve = 0\n\nwith tqdm(epochs) as tbar:\n    for epoch in tbar:\n        train_acc = train()\n\n        # Step the LR scheduler\n        scheduler.step(train_acc)\n\n        # Checkpoint saving\n        if train_acc > best:\n            best = train_acc\n            best_epoch = epoch\n            torch.save(model.state_dict(), \"best_model.pth\")\n            no_improve = 0\n        else:\n            no_improve += 1\n\n        # Early stopping\n        if no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n        tbar.set_description(f\"Train: {train_acc:.2f}, Best: {best:.2f} at epoch {best_epoch}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:28.103631Z","iopub.execute_input":"2025-10-27T18:11:28.103883Z","iopub.status.idle":"2025-10-27T18:11:28.115813Z","shell.execute_reply.started":"2025-10-27T18:11:28.103856Z","shell.execute_reply":"2025-10-27T18:11:28.115234Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Experiment 2:","metadata":{}},{"cell_type":"code","source":"# best = 0.0\n# best_epoch = 0\n# epochs = list(range(100))  # increase epochs; early stopping will break early\n# patience = 3\n# no_improve = 0\n\n# with tqdm(epochs) as tbar:\n#     for epoch in tbar:\n#         train_acc = train()\n\n#         # Step the LR scheduler\n#         scheduler.step(train_acc)\n\n#         # Checkpoint saving\n#         if train_acc > best:\n#             best = train_acc\n#             best_epoch = epoch\n#             torch.save(model.state_dict(), \"best_model.pth\")\n#             no_improve = 0\n#         else:\n#             no_improve += 1\n\n#         # Early stopping\n#         if no_improve >= patience:\n#             print(f\"Early stopping at epoch {epoch}\")\n#             break\n\n#         tbar.set_description(f\"Train: {train_acc:.2f}, Best: {best:.2f} at epoch {best_epoch}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:11:28.117857Z","iopub.execute_input":"2025-10-27T18:11:28.118121Z","iopub.status.idle":"2025-10-27T18:58:42.289132Z","shell.execute_reply.started":"2025-10-27T18:11:28.118092Z","shell.execute_reply":"2025-10-27T18:58:42.288425Z"}},"outputs":[{"name":"stderr","text":"Train: 95.82, Best: 95.82 at epoch 49: 100%|██████████| 50/50 [47:14<00:00, 56.68s/it]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Experiment 3","metadata":{}},{"cell_type":"code","source":"# best = 0.0\n# best_epoch = 0\n# epochs = list(range(100))  # increase epochs; early stopping will break early\n# patience = 3\n# no_improve = 0\n\n# with tqdm(epochs) as tbar:\n#     for epoch in tbar:\n#         train_acc, _ = train()   # <-- unpack tuple\n\n#         # Step the LR scheduler\n#         scheduler.step()  # keep as is for CosineAnnealing\n\n#         # Checkpoint saving\n#         if train_acc > best:\n#             best = train_acc\n#             best_epoch = epoch\n#             torch.save(model.state_dict(), \"best_model.pth\")\n#             no_improve = 0\n#         else:\n#             no_improve += 1\n\n#         # Early stopping\n#         if no_improve >= patience:\n#             print(f\"Early stopping at epoch {epoch}\")\n#             break\n\n#         tbar.set_description(f\"Train: {train_acc:.2f}, Best: {best:.2f} at epoch {best_epoch}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load the best checkpoint\n# if os.path.exists(\"best_model.pth\"):\n#     model.load_state_dict(torch.load(\"best_model.pth\"))\n#     print(\"Loaded best model checkpoint.\")\n# else:\n#     print(\"No checkpoint found, using current model.\")\n\n# Prepare submission\ndata = {\n    \"ID\": [],\n    \"target\": []\n}\n\nfor i, label in enumerate(inference()):\n    data[\"ID\"].append(i)\n    data[\"target\"].append(label)\n\ndf = pd.DataFrame(data)\ndf.to_csv(\"/kaggle/working/submission.csv\", index=False)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T18:58:42.290011Z","iopub.execute_input":"2025-10-27T18:58:42.290318Z","iopub.status.idle":"2025-10-27T18:58:44.429374Z","shell.execute_reply.started":"2025-10-27T18:58:42.290289Z","shell.execute_reply":"2025-10-27T18:58:44.428743Z"}},"outputs":[{"name":"stdout","text":"Loaded best model checkpoint.\n","output_type":"stream"}],"execution_count":14}]}